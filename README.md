# Rearchitecting-LLMs
Transform generic LLMs into specialized, fast and hyper-efficient models.

This repository contains a collection of Python notebooks and scripts focused on optimizing the architecture of Large Language Models.
The goal is to explore and practically demonstrate various structural modification techniques to improve the efficiency and fairness of the models.

## Content
The code explores, among other things, the following areas:

* Structured Pruning:
* Depth Pruning
* Width Pruning
* Optimization of Attention Mechanisms
* Knowledge Recovery post-optimization
* Analysis of Internal Activations for interpretability
* Fair Pruning: A methodology to mitigate biases directly in the model's architecture, combining efficiency and ethics.

