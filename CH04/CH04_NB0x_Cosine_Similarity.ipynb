{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOETqHxcxhCDiytrzJiZi0P",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/peremartra/Rearchitecting-LLMs/blob/main/CH04/CH04_NB0x_Cosine_Similarity.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Rearchitecting LLMs\n",
        "## Surgical Optimization for Hyper-Efficient Models\n",
        "\n",
        "\n",
        "###¬†Chapter 4: Depth Pruning: Building Smaller and Faster Models\n",
        "by [Pere Martra](https://github.com/peremartra)\n",
        "\n",
        "[![LinkedIn](https://img.shields.io/badge/LinkedIn-0077B5?style=flat&logo=linkedin&logoColor=white)](https://www.linkedin.com/in/pere-martra/) [![GitHub](https://img.shields.io/badge/GitHub-100000?style=flat&logo=github&logoColor=white)](https://github.com/peremartra) [![X](https://img.shields.io/badge/X-000000?style=flat&logo=x&logoColor=white)](https://x.com/PereMartra) [![Hugging Face](https://img.shields.io/badge/ü§ó%20Hugging%20Face-blue)](https://huggingface.co/oopere)\n",
        "\n",
        "_____\n",
        "Colab Environment: GPU T4\n",
        "\n",
        "Models:\n",
        "* Qwen3-0.6B\n",
        "_____\n",
        "\n",
        "In this notebook we explore how to evaluate the contribution of different transformer blocks to the LLM‚Äôs objective using a dataset.\n",
        "\n",
        "To do this, we use cosine similarity between the input and the output of the transformer block. The lower the similarity, the greater the modification that block has introduced to the data.\n",
        "\n",
        "Blocks with higher similarity between input and output will be the candidates to be removed from the model.\n"
      ],
      "metadata": {
        "id": "vf04d7qXqwUf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setting up notebook"
      ],
      "metadata": {
        "id": "3XUED5yYwoJz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q \\\n",
        "      \"torch==2.8.0+cu126\" \\\n",
        "      \"transformers==4.55.4\" \\\n",
        "      \"accelerate==1.10.1\" \\\n",
        "      \"lm_eval==0.4.9.1\" \\\n",
        "      \"sentencepiece==0.2.1\" \\\n",
        "      \"sentence-transformers==5.1.0\" \\\n",
        "      \"optipfair==0.1.5\""
      ],
      "metadata": {
        "id": "4AlU0F9Nu6xT",
        "outputId": "589c6d4e-18d2-413a-c881-c78213bcf126",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m42.0/42.0 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m53.6/53.6 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m39.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m7.5/7.5 MB\u001b[0m \u001b[31m25.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m483.4/483.4 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m44.9/44.9 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m491.5/491.5 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m293.6/293.6 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m104.1/104.1 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m51.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m91.1/91.1 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for rouge-score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for sqlitedict (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for word2number (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "from datasets import load_dataset\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm import tqdm\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "CCBC8p1FvBsV"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R5xvVourquO6",
        "outputId": "fb7eabf5-704d-4f68-957c-06fdd9ebe5d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "GPU: Tesla T4\n"
          ]
        }
      ],
      "source": [
        "# Check device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Model"
      ],
      "metadata": {
        "id": "ghFZPniOw0fp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_NAME = 'Qwen/Qwen3-0.6B'\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "if tokenizer.pad_token is None:\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    MODEL_NAME,\n",
        "    torch_dtype=torch.float16,\n",
        "    device_map=\"auto\"\n",
        ")\n",
        "model.eval()"
      ],
      "metadata": {
        "id": "MpLvzaifv_B6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Datasets"
      ],
      "metadata": {
        "id": "gP2pYvmfw3hV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "RECOVERY_SAMPLES = 100\n",
        "BATCH_SIZE = 8\n",
        "MAX_LENGTH = 512"
      ],
      "metadata": {
        "id": "B0INZII5BIMM"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We‚Äôre going to use two different datasets to visualize how some layers are more important than others depending on the data being used.\n",
        "\n",
        "* **Wikitext**: Contains highly complex text. To process this kind of text, the model needs to rely on its deeper layers to understand context, semantic relations, and complex grammatical structures.\n",
        "* **SMS Spam**: A completely different dataset, made up of short sentences with simple and direct language. It doesn‚Äôt require deep semantic understanding.\n"
      ],
      "metadata": {
        "id": "2epEOHrEbT36"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "datawiki = load_dataset('wikitext', 'wikitext-2-raw-v1', split=f'train[:100]')\n",
        "\n",
        "datasms = load_dataset('sms_spam', split=f'train[:100]')"
      ],
      "metadata": {
        "id": "0AxpLIebQoJe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_dataset(dataset, text_field='text'):\n",
        "  def tokenize_function(examples):\n",
        "      if text_field in examples:\n",
        "          texts = examples[text_field]\n",
        "      elif 'sms' in examples:  # SMS dataset\n",
        "          texts = examples['sms']\n",
        "      elif 'text' in examples:\n",
        "          texts = examples['text']\n",
        "      else:\n",
        "          texts = examples[list(examples.keys())[0]]  # First available field\n",
        "\n",
        "      return tokenizer(\n",
        "          texts,\n",
        "          truncation=True,\n",
        "          padding='max_length',\n",
        "          max_length=MAX_LENGTH,\n",
        "          return_tensors='pt'\n",
        "      )\n",
        "\n",
        "  tokenized = dataset.map(tokenize_function, batched=True, remove_columns=dataset.column_names)\n",
        "  tokenized.set_format(type='torch', columns=['input_ids', 'attention_mask'])\n",
        "  return DataLoader(tokenized, batch_size=BATCH_SIZE, shuffle=False)\n"
      ],
      "metadata": {
        "id": "8YAKyNaL6bqr"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear dataloaders\n",
        "dataloaderwiki = prepare_dataset(datawiki)  # WikiText (largo)\n",
        "dataloadersms = prepare_dataset(datasms)  # SMS (corto)"
      ],
      "metadata": {
        "id": "VDYfIVBFXj_9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4.2 Block Selection Strategies\n",
        "In this section, we're going to explore different strategies to make this decision. We'll start with the most direct and simple approaches, known as static or \"data-free\"\n",
        "# 4.2.1 Static Approaches (Data-Free)\n",
        "Static approaches are those based on analyzing the structure and initial weights of the model.\n"
      ],
      "metadata": {
        "id": "KCOV99WOlZoL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Based in position.\n",
        "from copy import deepcopy\n",
        "\n",
        "num_layers = len(model.model.layers)  # 32\n",
        "layers_to_keep = num_layers - 4\n",
        "print(f\"Number of layers: {num_layers}\")\n",
        "print(f\"Layers to keep: {layers_to_keep}\")\n",
        "\n",
        "pruned_model = deepcopy(model)\n",
        "pruned_model.model.layers = pruned_model.model.layers[:layers_to_keep]\n",
        "print(f\"Number of layers in pruned model: {len(pruned_model.model.layers)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7s61iZHnU0Yd",
        "outputId": "7408b5c4-3691-4a5a-81e9-4dc84bfa1b4c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of layers: 28\n",
            "Layers to keep: 24\n",
            "Number of layers in pruned model: 24\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Based in weigths\n",
        "def calculate_layer_magnitude(layer):\n",
        "    total_magnitude = 0\n",
        "    for param in layer.parameters():\n",
        "        total_magnitude += torch.norm(param).item()\n",
        "    return total_magnitude\n",
        "\n",
        "# Calculate magnitude for each layer\n",
        "layer_magnitudes = []\n",
        "for i, layer in enumerate(model.model.layers):\n",
        "    magnitude = calculate_layer_magnitude(layer)\n",
        "    layer_magnitudes.append((i, magnitude))\n",
        "\n",
        "# Remove layers with lower magnitude\n",
        "layer_magnitudes.sort(key=lambda x: x[1])  # Sort by magnitude\n",
        "layers_to_remove = [idx for idx, _ in layer_magnitudes[:4]]  # Remove layers with lower\n",
        "\n",
        "print(layers_to_remove)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TjmyRAOWl4ku",
        "outputId": "0a413c19-66fa-4934-d287-bef628fa1773"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[8, 2, 7, 6]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4.3 Data-driven analysis and pruning"
      ],
      "metadata": {
        "id": "58jFH4STU0_D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To decide which layers to remove, we measure their contribution using cosine similarity. We chose this metric because it‚Äôs perfect for this task: it measures the change in semantic direction between the input and output vectors of a layer, ignoring their magnitude.\n",
        "\n",
        "This gives us a normalized score that we convert into an importance score (1 - similarity).\n",
        "\n",
        "A score close to zero identifies a ‚Äúpassive‚Äù layer that barely alters the information, making it an ideal candidate for removal.\n"
      ],
      "metadata": {
        "id": "nGHINZat6ldT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.3.1 Using PyTorch hooks\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ECZxEn7TzICK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We define a simple function to use as a hook that shows the shape of the input tensor and the output tensor."
      ],
      "metadata": {
        "id": "7JckMkQF8B3L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def print_shape_hook(module, input, output):\n",
        "    \"\"\"\n",
        "    Hook function that prints tensor shapes\n",
        "    module: the layer where the hook is attached\n",
        "    input: tuple of input tensors to the layer\n",
        "    output: the output tensor from the layer\n",
        "    \"\"\"\n",
        "    # Input is a tuple, we take the first element (the hidden states)\n",
        "    print(f\"Module class: {module.__class__.__name__}\")\n",
        "    print(f\"Module id: {id(module)}\")\n",
        "    input_tensor = input[0]\n",
        "    print(f\"Input shape:  {input_tensor.shape}\")\n",
        "    print(f\"Output shape: {output.shape}\")"
      ],
      "metadata": {
        "id": "opHXnaK74FKk"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We register the hook in the first transformer block.Retry"
      ],
      "metadata": {
        "id": "p0uuj7VN8IiO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Register the hook on the first transformer block\n",
        "first_layer = model.model.layers[0]\n",
        "hook_handle = first_layer.register_forward_hook(print_shape_hook)"
      ],
      "metadata": {
        "id": "2F2sONdy4_-t"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We run a forward with the model and get the hook result that Pytorch executes automatically."
      ],
      "metadata": {
        "id": "N6XEfZCm-bHU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Test with a simple input\n",
        "test_text = \"He sat on the river bank to fish\"\n",
        "inputs = tokenizer(test_text, return_tensors=\"pt\").to(device)\n",
        "with torch.no_grad():\n",
        "    outputs = model(**inputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A3jfBz7N5elD",
        "outputId": "324cc795-dcad-42a5-d25a-6ac965125fd4"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Module class: Qwen3DecoderLayer\n",
            "Module id: 139373042887584\n",
            "Input shape:  torch.Size([1, 8, 1024])\n",
            "Output shape: torch.Size([1, 8, 1024])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We remove the hooks."
      ],
      "metadata": {
        "id": "_p7LALtN_BVn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove the hook when done\n",
        "hook_handle.remove()"
      ],
      "metadata": {
        "id": "J-aitGMa5vOp"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If we run the forward again, the hook no longer executesRetry"
      ],
      "metadata": {
        "id": "MLJnxUbY_B_T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    outputs = model(**inputs)"
      ],
      "metadata": {
        "id": "IL4rZJJy5slH"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.3.2 Understanding cosine similarity."
      ],
      "metadata": {
        "id": "sehVQjflwkOS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Load standard sentence embedding model\n",
        "modelst = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "# Three example sentences: two semantically similar, one different\n",
        "sentences = [\n",
        "    \"The cat naps on the sofa.\",\n",
        "    \"The feline is peacefully slumbering on the couch.\",\n",
        "    \"The bus stops at the corner.\"\n",
        "]\n",
        "\n",
        "embeddings = modelst.encode(sentences, convert_to_tensor=True)\n",
        "\n",
        "print(f\"Embedding shape: {embeddings.shape}\")\n",
        "print(f\"Each sentence is represented by {embeddings.shape[1]} dimensions\\n\")\n",
        "\n",
        "# Calculate cosine similarity matrix using PyTorch\n",
        "# We need to compute all pairs, so we use matrix multiplication\n",
        "# First normalize embeddings\n",
        "embeddings_normalized = F.normalize(embeddings, p=2, dim=1)\n",
        "\n",
        "# Compute similarity matrix (cosine = dot product of normalized vectors)\n",
        "similarity_matrix = torch.mm(embeddings_normalized, embeddings_normalized.T)\n",
        "\n",
        "print(\"Cosine Similarity Matrix:\")\n",
        "print(similarity_matrix)\n",
        "print(\"\\nInterpretation:\")\n",
        "print(f\"Sentence 1 vs Sentence 2: {similarity_matrix[0][1]:.4f} (semantically similar)\")\n",
        "print(f\"Sentence 1 vs Sentence 3: {similarity_matrix[0][2]:.4f} (different topics)\")\n",
        "print(\"\\nNote: Values close to 1.0 indicate high similarity\")\n"
      ],
      "metadata": {
        "id": "Wvq73_GVwnRh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.3.3 Measuring Block Importance\n"
      ],
      "metadata": {
        "id": "Af4D7jK87Kud"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To capture the input and output of the layers we use PyTorch hooks, which let us study/spy on the model‚Äôs behavior.\n"
      ],
      "metadata": {
        "id": "IC3EkRvAeZWH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def setup_layer_hooks(model):\n",
        "    \"\"\"\n",
        "    Register hooks to capture input/output of each transformer layer\n",
        "    Returns: hooks list and storage dictionaries\n",
        "    \"\"\"\n",
        "    num_layers = len(model.model.layers)\n",
        "    layer_inputs = {}\n",
        "    layer_outputs = {}\n",
        "    hooks = []\n",
        "\n",
        "    def create_hook(layer_idx): #B\n",
        "        def hook(module, input, output): #C\n",
        "            # Captura la entrada del bloque\n",
        "            input_tensor = input[0] if isinstance(input, tuple) else input\n",
        "            layer_inputs[layer_idx] = input_tensor.detach().cpu() #D\n",
        "\n",
        "            # Captura la salida del bloque\n",
        "            output_tensor = output[0] if isinstance(output, tuple) else output\n",
        "            layer_outputs[layer_idx] = output_tensor.detach().cpu() #D\n",
        "        return hook\n",
        "\n",
        "    # Register hooks for each layer\n",
        "    for i, layer in enumerate(model.model.layers):\n",
        "        hooks.append(\n",
        "            layer.register_forward_hook(create_hook(i))\n",
        "            )\n",
        "\n",
        "    return hooks, layer_inputs, layer_outputs, num_layers"
      ],
      "metadata": {
        "id": "vT40G6hq6itp"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Calculate Cosine Similarity"
      ],
      "metadata": {
        "id": "qBTC2Dh97jx4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_cosine_importance(input_tensor, output_tensor, layer_idx, is_first_batch=False):\n",
        "    \"\"\"\n",
        "    Calculate importance score using cosine similarity between input and output tensors.\n",
        "    Optimized for GPU by computing similarity on full batch before filtering.\n",
        "\n",
        "    Args:\n",
        "        input_tensor: Input hidden states to the layer\n",
        "        output_tensor: Output hidden states from the layer\n",
        "        layer_idx: Layer index for debugging\n",
        "        is_first_batch: Whether to print debug warnings\n",
        "\n",
        "    Returns:\n",
        "        importance: Score from 0.0 to 1.0 (higher = more important)\n",
        "    \"\"\"\n",
        "    # Validate tensor dimensions\n",
        "    if input_tensor.numel() == 0 or output_tensor.numel() == 0:\n",
        "        return 0.0\n",
        "\n",
        "    # Flatten tensors to [batch_size, features]\n",
        "    input_flat = input_tensor.view(input_tensor.size(0), -1)\n",
        "    output_flat = output_tensor.view(output_tensor.size(0), -1)\n",
        "\n",
        "    # Compute cosine similarity for entire batch (GPU-optimized)\n",
        "    similarities = F.cosine_similarity(input_flat, output_flat, dim=1)\n",
        "\n",
        "    # Filter non-finite values after computation\n",
        "    finite_similarities = similarities[torch.isfinite(similarities)]\n",
        "\n",
        "    # Handle case with no valid samples\n",
        "    if finite_similarities.numel() == 0:\n",
        "        if is_first_batch:\n",
        "            print(f\"Warning: Layer {layer_idx} produced all inf/nan similarities\")\n",
        "        return 0.0\n",
        "\n",
        "    # Importance = 1 - average similarity\n",
        "    # (low similarity = high change = high importance)\n",
        "    importance = 1.0 - finite_similarities.mean().item()\n",
        "\n",
        "    return importance"
      ],
      "metadata": {
        "id": "VYCdoz0ekTHS"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We aggregate the results"
      ],
      "metadata": {
        "id": "VkbDmAVNewak"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def aggregate_importance_scores(layer_scores):\n",
        "    \"\"\"\n",
        "    Aggregate importance scores across all batches\n",
        "    Returns: dictionary with final averaged scores per layer\n",
        "    \"\"\"\n",
        "    final_scores = {}\n",
        "    for layer_idx, scores in layer_scores.items():\n",
        "        if scores:\n",
        "            # Filter out invalid scores\n",
        "            valid_scores = [s for s in scores if not (np.isnan(s) or np.isinf(s))]\n",
        "            final_scores[layer_idx] = np.mean(valid_scores) if valid_scores else 0.0\n",
        "        else:\n",
        "            final_scores[layer_idx] = 0.0\n",
        "\n",
        "    return final_scores\n"
      ],
      "metadata": {
        "id": "dI5dJlfK7qMa"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This function takes the importance scores collected from all data batches for each layer. Then, it computes the average of these scores to get a single final consolidated importance score for each layer of the model."
      ],
      "metadata": {
        "id": "AL33kTqtfbz_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_layer_importance_cosine(model, dataloader, device):\n",
        "    \"\"\"\n",
        "    Calculate layer importance using cosine similarity between input/output representations\n",
        "\n",
        "    Args:\n",
        "        model: Transformer model\n",
        "        dataloader: DataLoader with tokenized text data\n",
        "        device: torch device (cuda/cpu)\n",
        "\n",
        "    Returns:\n",
        "        dict: Layer importance scores {layer_idx: importance_score}\n",
        "    \"\"\"\n",
        "    # Setup hooks and storage\n",
        "    hooks, layer_inputs, layer_outputs, num_layers = setup_layer_hooks(model)\n",
        "    layer_importance_scores = {i: [] for i in range(num_layers)}\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, batch in enumerate(tqdm(dataloader, desc=\"Processing batches\")):\n",
        "            inputs = {k: v.to(device) for k, v in batch.items()}\n",
        "\n",
        "            # Forward pass to trigger hooks\n",
        "            model(**inputs)\n",
        "\n",
        "            # Calculate importance for each layer\n",
        "            for layer_idx in range(num_layers):\n",
        "                if layer_idx not in layer_inputs or layer_idx not in layer_outputs:\n",
        "                    layer_importance_scores[layer_idx].append(0.0)\n",
        "                    continue\n",
        "\n",
        "                input_tensor = layer_inputs[layer_idx]\n",
        "                output_tensor = layer_outputs[layer_idx]\n",
        "\n",
        "                importance = calculate_cosine_importance(\n",
        "                    input_tensor, output_tensor, layer_idx,\n",
        "                    is_first_batch=(batch_idx == 0)\n",
        "                )\n",
        "                layer_importance_scores[layer_idx].append(importance)\n",
        "\n",
        "            # Clear storage for next batch\n",
        "            layer_inputs.clear()\n",
        "            layer_outputs.clear()\n",
        "\n",
        "    # Cleanup hooks\n",
        "    for hook in hooks:\n",
        "        hook.remove()\n",
        "\n",
        "    # Aggregate final scores\n",
        "    final_scores = aggregate_importance_scores(layer_importance_scores)\n",
        "\n",
        "    return final_scores"
      ],
      "metadata": {
        "id": "iRjXO8fd7uWz"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Obtaining & Studying results"
      ],
      "metadata": {
        "id": "LXZvQP6Ufge-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def print_sorted_importance(scores):\n",
        "    for i, (layer, score) in enumerate(sorted(scores.items(), key=lambda x: float(x[1]), reverse=True), 1):\n",
        "        print(f\"Layer {layer:2d}: {float(score):.6f}\")"
      ],
      "metadata": {
        "id": "KxECy2RMVKaN"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wiki_importance= calculate_layer_importance_cosine(model, dataloaderwiki, device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iw68nEqr76P-",
        "outputId": "afd6e699-8025-4b06-d171-0289a8dbbd0a"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:18<00:00,  1.41s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_sorted_importance(wiki_importance)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uebaKFEe8GpS",
        "outputId": "3dfc4a75-1d70-4f9a-eed6-705c858300ef"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layer  0: 0.890400\n",
            "Layer  2: 0.771517\n",
            "Layer  1: 0.307429\n",
            "Layer 27: 0.172739\n",
            "Layer 23: 0.082144\n",
            "Layer 25: 0.074031\n",
            "Layer 24: 0.071702\n",
            "Layer 22: 0.068585\n",
            "Layer 26: 0.062951\n",
            "Layer 21: 0.061974\n",
            "Layer 17: 0.059157\n",
            "Layer 19: 0.053673\n",
            "Layer  4: 0.050105\n",
            "Layer 16: 0.049730\n",
            "Layer 11: 0.048640\n",
            "Layer  9: 0.047213\n",
            "Layer 13: 0.046387\n",
            "Layer  5: 0.046011\n",
            "Layer  6: 0.045147\n",
            "Layer  3: 0.043532\n",
            "Layer 15: 0.043307\n",
            "Layer 14: 0.043232\n",
            "Layer 12: 0.042030\n",
            "Layer 10: 0.041466\n",
            "Layer 20: 0.041466\n",
            "Layer  8: 0.037861\n",
            "Layer 18: 0.036358\n",
            "Layer  7: 0.031100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sms_importance = calculate_layer_importance_cosine(model, dataloadersms, device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "QTywurOkR7Cm",
        "outputId": "c046b9a3-f9e3-4bb8-a3d2-555f420036c5"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:33<00:00,  2.60s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_sorted_importance(sms_importance)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "rPKWuhurSUpe",
        "outputId": "6973a434-dfa8-4efc-e790-1d3b1384e363"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layer  2: 0.948613\n",
            "Layer  0: 0.896977\n",
            "Layer  1: 0.276968\n",
            "Layer 27: 0.146635\n",
            "Layer 21: 0.024264\n",
            "Layer 24: 0.022461\n",
            "Layer 25: 0.020207\n",
            "Layer 26: 0.016677\n",
            "Layer 22: 0.016564\n",
            "Layer 20: 0.015512\n",
            "Layer 19: 0.014273\n",
            "Layer 23: 0.013897\n",
            "Layer 18: 0.007061\n",
            "Layer 17: 0.004432\n",
            "Layer 16: 0.003869\n",
            "Layer 15: 0.002779\n",
            "Layer 14: 0.002441\n",
            "Layer 11: 0.001878\n",
            "Layer 10: 0.001427\n",
            "Layer 12: 0.001127\n",
            "Layer 13: 0.001052\n",
            "Layer  9: 0.000338\n",
            "Layer  3: 0.000113\n",
            "Layer  5: 0.000038\n",
            "Layer  4: 0.000000\n",
            "Layer  6: 0.000000\n",
            "Layer  7: 0.000000\n",
            "Layer  8: 0.000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def compare_importance(scores1, scores2, name1=\"Dataset1\", name2=\"Dataset2\"):\n",
        "    print(f\"{'Layer':<5} {name1:<10} {name2:<10} {'Diff':<8}\")\n",
        "    print(\"-\" * 35)\n",
        "    for layer in sorted(scores1.keys()):\n",
        "        s1, s2 = float(scores1[layer]), float(scores2[layer])\n",
        "        diff = abs(s1 - s2)\n",
        "        print(f\"{layer:<5} {s1:<10.4f} {s2:<10.4f} {diff:<8.4f}\")"
      ],
      "metadata": {
        "id": "7a63I8HvUnIm"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "compare_importance(wiki_importance, sms_importance, \"wiki\", \"SMS\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "_IBQcFl8gyI_",
        "outputId": "7e7c4621-7d20-411f-d2e3-5a64a5086e2c"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layer wiki       SMS        Diff    \n",
            "-----------------------------------\n",
            "0     0.8904     0.8970     0.0066  \n",
            "1     0.3074     0.2770     0.0305  \n",
            "2     0.7715     0.9486     0.1771  \n",
            "3     0.0435     0.0001     0.0434  \n",
            "4     0.0501     0.0000     0.0501  \n",
            "5     0.0460     0.0000     0.0460  \n",
            "6     0.0451     0.0000     0.0451  \n",
            "7     0.0311     0.0000     0.0311  \n",
            "8     0.0379     0.0000     0.0379  \n",
            "9     0.0472     0.0003     0.0469  \n",
            "10    0.0415     0.0014     0.0400  \n",
            "11    0.0486     0.0019     0.0468  \n",
            "12    0.0420     0.0011     0.0409  \n",
            "13    0.0464     0.0011     0.0453  \n",
            "14    0.0432     0.0024     0.0408  \n",
            "15    0.0433     0.0028     0.0405  \n",
            "16    0.0497     0.0039     0.0459  \n",
            "17    0.0592     0.0044     0.0547  \n",
            "18    0.0364     0.0071     0.0293  \n",
            "19    0.0537     0.0143     0.0394  \n",
            "20    0.0415     0.0155     0.0260  \n",
            "21    0.0620     0.0243     0.0377  \n",
            "22    0.0686     0.0166     0.0520  \n",
            "23    0.0821     0.0139     0.0682  \n",
            "24    0.0717     0.0225     0.0492  \n",
            "25    0.0740     0.0202     0.0538  \n",
            "26    0.0630     0.0167     0.0463  \n",
            "27    0.1727     0.1466     0.0261  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def compare_importance(scores1, scores2, name1=\"Dataset1\", name2=\"Dataset2\",\n",
        "                      start=None, end=None, model=\"Qwen3-0.6B\"):\n",
        "    layers = sorted(scores1.keys())\n",
        "    if start is not None or end is not None:\n",
        "        layers = [l for l in layers if (start is None or l >= start) and\n",
        "                 (end is None or l <= end)]\n",
        "\n",
        "    vals1 = [float(scores1[l]) for l in layers]\n",
        "    vals2 = [float(scores2[l]) for l in layers]\n",
        "\n",
        "    x = np.arange(len(layers))\n",
        "    width = 0.35\n",
        "\n",
        "    plt.figure(figsize=(10, 4))\n",
        "    plt.bar(x - width/2, vals1, width, label=name1, alpha=0.7)\n",
        "    plt.bar(x + width/2, vals2, width, label=name2, alpha=0.7)\n",
        "\n",
        "    plt.xlabel('Transformer Block')\n",
        "    plt.ylabel('Cosine Distance')\n",
        "    plt.xticks(x, layers)\n",
        "    plt.legend()\n",
        "    plt.title(f\"Transformer Block Importance on {model}: SMS vs. WikiText\")\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "BVLe5ePEzH26"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "compare_importance(wiki_importance, sms_importance, name1=\"wikitext\", name2=\"SMS_spam\", start=3, end=20)"
      ],
      "metadata": {
        "id": "ZYEu7GhWzUjB",
        "outputId": "2889445f-ddc4-4401-e615-a7b48bc142e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        }
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x400 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The results of our comparison reveal a clear pattern. The first layers (0‚Äì2) and the last one (27) prove to be important in both datasets, suggesting that they perform fundamental functions, such as the initial processing of the input and the consolidation of the output.\n",
        "\n",
        "The key difference lies in the behavior of the intermediate layers (roughly 3‚Äì26). While in the complex text of Wikitext these layers carry out a measurable job of semantic refinement, in the simple SMS text their contribution is practically null, becoming ‚Äúpassive.‚Äù This shows that the importance of a layer varies depending on the complexity of the task, thus validating ‚Äúdepth pruning‚Äù as an effective strategy to create more efficient models for specialized tasks.\n"
      ],
      "metadata": {
        "id": "yw3B3bVZia7W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create the pruned model for the SMS dataset by removing the 4 least relevant layers."
      ],
      "metadata": {
        "id": "9LN1lqRsnh9y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can use the information obtained to remove the less important Transfomer blocks from the model to be used with the SMS Dataset."
      ],
      "metadata": {
        "id": "gGA5DjnSocOW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from optipfair import prune_model\n",
        "\n",
        "sms_model, stats = prune_model(\n",
        "    model=deepcopy(model),\n",
        "    pruning_type=\"DEPTH\",\n",
        "    layer_indices=[3, 4, 5, 6],\n",
        "    show_progress=True,\n",
        "    return_stats=True\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "DE0DLlJong2Z",
        "outputId": "49900b06-267b-4570-f628-8f072ad810a8"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Removing layers: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 28/28 [00:00<00:00, 326223.64it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The new model has only 24 transformer blocks."
      ],
      "metadata": {
        "id": "TQkngm7uoWbH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print (stats['percentage_reduction'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "GoiVSUm8o5XU",
        "outputId": "18374cf4-174a-45db-ef02-9de62e2daa43"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10.556796316657504\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(sms_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "vvHU8hC3hSzm",
        "outputId": "f4970949-dd18-4117-f079-b80d2b821b8d"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Qwen3ForCausalLM(\n",
            "  (model): Qwen3Model(\n",
            "    (embed_tokens): Embedding(151936, 1024)\n",
            "    (layers): ModuleList(\n",
            "      (0-23): 24 x Qwen3DecoderLayer(\n",
            "        (self_attn): Qwen3Attention(\n",
            "          (q_proj): Linear(in_features=1024, out_features=2048, bias=False)\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
            "          (o_proj): Linear(in_features=2048, out_features=1024, bias=False)\n",
            "          (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
            "          (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
            "        )\n",
            "        (mlp): Qwen3MLP(\n",
            "          (gate_proj): Linear(in_features=1024, out_features=3072, bias=False)\n",
            "          (up_proj): Linear(in_features=1024, out_features=3072, bias=False)\n",
            "          (down_proj): Linear(in_features=3072, out_features=1024, bias=False)\n",
            "          (act_fn): SiLU()\n",
            "        )\n",
            "        (input_layernorm): Qwen3RMSNorm((1024,), eps=1e-06)\n",
            "        (post_attention_layernorm): Qwen3RMSNorm((1024,), eps=1e-06)\n",
            "      )\n",
            "    )\n",
            "    (norm): Qwen3RMSNorm((1024,), eps=1e-06)\n",
            "    (rotary_emb): Qwen3RotaryEmbedding()\n",
            "  )\n",
            "  (lm_head): Linear(in_features=1024, out_features=151936, bias=False)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating WikiModel using optipfair."
      ],
      "metadata": {
        "id": "GJZ8Hlpe9JCb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from optipfair import analyze_layer_importance, prune_model_depth, prune_model"
      ],
      "metadata": {
        "id": "JUHY9cE-_B6D"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "wiki_scores = analyze_layer_importance(model,\n",
        "                                       dataloaderwiki,\n",
        "                                       show_progress=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "nYzO4oOO9Iia",
        "outputId": "1a26ce8f-a236-45f6-cdf7-fd5a7add6c45"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:05<00:00,  2.44it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "layers_2_remove = sorted(wiki_scores.keys(), key=lambda x: wiki_scores[x])[:4]\n",
        "print (layers_2_remove)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "nX_4Bzqt8gWo",
        "outputId": "e15f0c83-5e29-4389-d100-842fb4d3a230"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[7, 18, 8, 20]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wiki_model = prune_model(\n",
        "        model=deepcopy(model),\n",
        "        pruning_type=\"DEPTH\",\n",
        "        layer_indices=layers_2_remove,\n",
        "        show_progress=True,\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "O-W11SMA-Jjy",
        "outputId": "c131b46a-f926-44cc-e692-ddf2fadb7e97"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Removing layers: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 28/28 [00:00<00:00, 337472.74it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wiki_model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "rQciMIKQDK-G",
        "outputId": "768280f2-9190-4dde-a5a1-9d68790c90f9"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Qwen3ForCausalLM(\n",
              "  (model): Qwen3Model(\n",
              "    (embed_tokens): Embedding(151936, 1024)\n",
              "    (layers): ModuleList(\n",
              "      (0-23): 24 x Qwen3DecoderLayer(\n",
              "        (self_attn): Qwen3Attention(\n",
              "          (q_proj): Linear(in_features=1024, out_features=2048, bias=False)\n",
              "          (k_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
              "          (v_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
              "          (o_proj): Linear(in_features=2048, out_features=1024, bias=False)\n",
              "          (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
              "          (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
              "        )\n",
              "        (mlp): Qwen3MLP(\n",
              "          (gate_proj): Linear(in_features=1024, out_features=3072, bias=False)\n",
              "          (up_proj): Linear(in_features=1024, out_features=3072, bias=False)\n",
              "          (down_proj): Linear(in_features=3072, out_features=1024, bias=False)\n",
              "          (act_fn): SiLU()\n",
              "        )\n",
              "        (input_layernorm): Qwen3RMSNorm((1024,), eps=1e-06)\n",
              "        (post_attention_layernorm): Qwen3RMSNorm((1024,), eps=1e-06)\n",
              "      )\n",
              "    )\n",
              "    (norm): Qwen3RMSNorm((1024,), eps=1e-06)\n",
              "    (rotary_emb): Qwen3RotaryEmbedding()\n",
              "  )\n",
              "  (lm_head): Linear(in_features=1024, out_features=151936, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    }
  ]
}