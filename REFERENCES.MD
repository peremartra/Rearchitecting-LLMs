## Chapter 1: Why model rearchitecting matters

Bhattacharyya, C., & Kim, Y. (2025). FineScope : Precision Pruning for Domain-Specialized Large Language Models Using SAE-Guided Self-Data Cultivation. http://arxiv.org/abs/2505.00624

* Finescope is used as an example of the efficiency that can be achieved by using a data-driven re-architecture.

Sreenivas, S. T., Muralidharan, S., Joshi, R., Chochowski, M., Mahabaleshwarkar, A. S., Shen, G., Zeng, J., Chen, Z., Suhara, Y., Diao, S., Yu, C., Chen, W.-C., Ross, H., Olabiyi, O., Aithal, A., Kuchaiev, O., Korzekwa, D., Molchanov, P., Patwary, M., … Catanzaro, B. (2024). LLM Pruning and Distillation in Practice: The Minitron Approach. http://arxiv.org/abs/2408.11796

* NVIDIA's framework for creating its models is based on the inspiration from the tailoring pipeline flow presented in the chapter.

## Chapter 2: Rearchitecting a LLM
Kim, B.-K., Kim, G., Kim, T.-H., Castells, T., Choi, S., Shin, J., & Song, H.-K. (2024). Shortened LLaMA: Depth Pruning for Large Language Models with Comparison of Retraining Methods. http://arxiv.org/abs/2402.02834

* Although it's an introductory chapter to the depth pruning technique, part of the explanations and methodology are based on the paper's findings.
